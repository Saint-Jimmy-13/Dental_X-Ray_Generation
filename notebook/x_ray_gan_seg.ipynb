{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Synthetic Dental X-Ray Generation and Segmentation Analysis**"
      ],
      "metadata": {
        "id": "u0m-F0njto2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "uXr2ffU4url4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "YozenHtdojDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, time, random, sys\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid, save_image\n",
        "import torch.optim as optim\n",
        "\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "dGUOMmweyeVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment report"
      ],
      "metadata": {
        "id": "9g1ZJM_gokmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Environment\")\n",
        "print(\"-----------\")\n",
        "print(f\"Python        : {sys.version.split()[0]}\")\n",
        "print(f\"NumPy         : {np.__version__}\")\n",
        "print(f\"PyTorch       : {torch.__version__}\")\n",
        "print(f\"OpenCV        : {cv2.__version__}\")\n",
        "print()\n",
        "\n",
        "# CUDA / device check\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA available\")\n",
        "    print(f\"GPU           : {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version  : {torch.version.cuda}\")\n",
        "    print(f\"cuDNN         : {torch.backends.cudnn.version()}\")\n",
        "else:\n",
        "    print(\"CUDA NOT available (training will be slow)\")"
      ],
      "metadata": {
        "id": "xAAovxKuonMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Globals"
      ],
      "metadata": {
        "id": "OByRHGuyutA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 13\n",
        "PROJECT_ROOT = Path(\"../workspace\")\n",
        "DATA_ROOT_IMG = PROJECT_ROOT / \"teeth_seg_dataset/d2/img\"\n",
        "MASK_DIR = PROJECT_ROOT / \"teeth_seg_dataset/d2/masks_machine\"\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "CHANNELS = 1\n",
        "EPOCHS = 10\n",
        "LR = 2e-4\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "LATENT_DIM = 100\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.999"
      ],
      "metadata": {
        "id": "r7irBg5Y6Xsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "2AnA1lt1uu7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int=13):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)"
      ],
      "metadata": {
        "id": "geDVSgQy9NEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_to_square(img, fill=0):\n",
        "    w, h = img.size\n",
        "    if w == h: return img\n",
        "    s = max(w, h)\n",
        "    out = Image.new(img.mode, (s, s), color=fill)\n",
        "    out.paste(img, ((s - w) // 2, (s - h) // 2))\n",
        "    return out"
      ],
      "metadata": {
        "id": "kuAU4-QwJFeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_tensor_gray(img):\n",
        "    if img.mode != \"L\": img = img.convert(\"L\")\n",
        "    arr = np.array(img, dtype=np.float32) / 255.0   # (H, W)\n",
        "    arr = arr[None, ...]    # (1, H, W)\n",
        "    return torch.from_numpy(arr)"
      ],
      "metadata": {
        "id": "tjS4AM35MiYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denorm(x):\n",
        "    # [-1, 1] -> [0, 1]\n",
        "    return (x.clamp(-1, 1) + 1) * 0.5"
      ],
      "metadata": {
        "id": "PG7nWjhDNs5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_grid(t, nrow=8, title=None):\n",
        "    g = make_grid(denorm(t.detach().cpu()), nrow=nrow, padding=2)\n",
        "    g_np = g.squeeze(0).permute(1, 2, 0).numpy()\n",
        "    plt.figure(figsize=(22, 16), dpi=160)\n",
        "    plt.axis(\"off\")\n",
        "    if title: plt.title(title)\n",
        "    plt.imshow(g_np.squeeze(), cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bccrY4iXN5s7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "5fIbWdCiuv3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_image_files(root):\n",
        "    return sorted(glob.glob(os.path.join(root, \"**\", \"*.jpg\"), recursive=True))\n",
        "\n",
        "class DentalXRays(Dataset):\n",
        "    def __init__(self, root, size=256):\n",
        "        super().__init__()\n",
        "        self.paths = list_image_files(root)\n",
        "        self.size = size\n",
        "        if not self.paths:\n",
        "            print(f\"[WARNING] No .jpg images found under: {root}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        img = Image.open(p).convert(\"L\")\n",
        "        img = pad_to_square(img, fill=0)\n",
        "        img = img.resize((self.size, self.size), resample=Image.BICUBIC)\n",
        "        t = to_tensor_gray(img) # [0, 1]\n",
        "        t = t * 2.0 - 1.0   # [-1, 1] for GAN\n",
        "        return t"
      ],
      "metadata": {
        "id": "_GmkF-TAJLZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DentalXRays(DATA_ROOT_IMG, IMG_SIZE)\n",
        "if len(dataset) == 0:\n",
        "    raise RuntimeError(f\"No .jpg images in {DATA_ROOT_IMG}\")\n",
        "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "\n",
        "# Quick visual sanity check\n",
        "batch = next(iter(loader))\n",
        "show_grid(batch[:16], nrow=4, title=\"Real images (normalized, d2/img)\")\n",
        "print(f\"Loaded {len(dataset)} .jpg images from {DATA_ROOT_IMG}\")\n",
        "print(batch.size())"
      ],
      "metadata": {
        "id": "7XRAVwLlNMdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "8mkbbopguxqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Vanilla GAN"
      ],
      "metadata": {
        "id": "3_QEbY9jRyXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 8 * 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 8, 8)),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=0.78),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        return img"
      ],
      "metadata": {
        "id": "GilVhqdERx51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # self.model = nn.Sequential(\n",
        "        # nn.Conv2d(1, 256, kernel_size=3, stride=2, padding=1),\n",
        "        # nn.LeakyReLU(0.2),\n",
        "        # nn.Dropout(0.25),\n",
        "        # nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
        "        # nn.ZeroPad2d((0, 1, 0, 1)),\n",
        "        # nn.BatchNorm2d(512, momentum=0.82),\n",
        "        # nn.LeakyReLU(0.25),\n",
        "        # nn.Dropout(0.25),\n",
        "        # nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1),\n",
        "        # nn.BatchNorm2d(1024, momentum=0.82),\n",
        "        # nn.LeakyReLU(0.2),\n",
        "        # nn.Dropout(0.25),\n",
        "        # nn.Conv2d(1024, 2048, kernel_size=3, stride=1, padding=1),\n",
        "        # nn.BatchNorm2d(2048, momentum=0.8),\n",
        "        # nn.LeakyReLU(0.25),\n",
        "        # nn.Dropout(0.25),\n",
        "        # nn.Flatten(),\n",
        "        # nn.Linear(2048 * 8 * 8, 1),\n",
        "        # nn.Sigmoid()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ZeroPad2d((0, 1, 0, 1)),\n",
        "            nn.BatchNorm2d(64, momentum=0.82),\n",
        "            nn.LeakyReLU(0.25),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.82),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, momentum=0.8),\n",
        "            nn.LeakyReLU(0.25),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 8 * 8, 1),\n",
        "            nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "kwUw30euSkoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "6qD4Xdxsu0Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Vanilla GAN"
      ],
      "metadata": {
        "id": "iyFrpy7mSv2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(LATENT_DIM).to(DEVICE)\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=LR, betas=(BETA1, BETA2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=LR, betas=(BETA1, BETA2))"
      ],
      "metadata": {
        "id": "FG8yNpS8SvLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    for i, batch in tqdm(enumerate(loader)):\n",
        "\n",
        "        real_images = batch.to(DEVICE)\n",
        "\n",
        "        valid = torch.ones(real_images.size(0), 1, device=DEVICE)\n",
        "        fake = torch.zeros(real_images.size(0), 1, device=DEVICE)\n",
        "\n",
        "        real_images = real_images.to(DEVICE)\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        z = torch.randn(real_images.size(0), LATENT_DIM, device=DEVICE)\n",
        "\n",
        "        fake_images = generator(z)\n",
        "\n",
        "        real_loss = adversarial_loss(discriminator(real_images), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(fake_images.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        gen_images = generator(z)\n",
        "\n",
        "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(\n",
        "                f\"Epoch [{epoch+1}/{EPOCHS}]\\\n",
        "                        Batch {i+1}/{len(loader)} \"\n",
        "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
        "            )\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(16, LATENT_DIM, device=DEVICE)\n",
        "            generated = generator(z).detach().cpu()\n",
        "            grid = make_grid(generated, nrow=4, normalize=True)\n",
        "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "eN9sNGa8TFk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "kfB1-ZQau1I1"
      }
    }
  ]
}